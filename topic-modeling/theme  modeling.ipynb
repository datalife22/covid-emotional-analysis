{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1808ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c70476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf55f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [line.strip() for line in open('stop.txt', 'r', encoding='utf-8').readlines()]\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3909e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_word(s):\n",
    "    a = word_tokenize(s) \n",
    "    b = []\n",
    "    for i in a:\n",
    "        i = i.lower()\n",
    "        i = wordnet_lemmatizer.lemmatize(i, 'n')\n",
    "        i = wordnet_lemmatizer.lemmatize(i, 'v')\n",
    "        b.append(i)\n",
    "    o = ''\n",
    "    for word in b:\n",
    "        c = re.sub(\"[a-zA-Z]\", \"\", word)\n",
    "        if len(c) == 0 and word not in stopwords and len(word) > 2:\n",
    "            o += word\n",
    "            o += \" \"\n",
    "    return o.split(' ')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf69e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['result'] = df[\"sentence\"].apply(cut_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67642f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(df['result'])\n",
    "corpus = [dictionary.doc2bow(i) for i in df['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b729ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "lda_model = models.LdaModel(corpus, alpha=1/k,  iterations=50, gamma_threshold=0.1,num_topics=k, id2word=dictionary, chunksize=100,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef4e57a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.077*\"rest\" + 0.061*\"work\" + 0.028*\"parent\" + 0.024*\"child\" + 0.023*\"woman\" + 0.022*\"panic\" + 0.022*\"party\" + 0.018*\"pandemic\" + 0.015*\"force\" + 0.014*\"safe\"'),\n",
       " (1,\n",
       "  '0.041*\"buy\" + 0.036*\"government\" + 0.024*\"care\" + 0.023*\"die\" + 0.021*\"kid\" + 0.021*\"lose\" + 0.020*\"win\" + 0.016*\"fear\" + 0.013*\"break\" + 0.012*\"choose\"'),\n",
       " (2,\n",
       "  '0.051*\"christmas\" + 0.049*\"family\" + 0.033*\"money\" + 0.032*\"love\" + 0.026*\"lock\" + 0.022*\"sick\" + 0.021*\"start\" + 0.020*\"worry\" + 0.015*\"remember\" + 0.015*\"reason\"'),\n",
       " (3,\n",
       "  '0.049*\"close\" + 0.032*\"join\" + 0.025*\"return\" + 0.023*\"lead\" + 0.021*\"rise\" + 0.020*\"border\" + 0.017*\"set\" + 0.016*\"door\" + 0.015*\"earn\" + 0.015*\"infection\"'),\n",
       " (4,\n",
       "  '0.107*\"epidemic\" + 0.052*\"scar\" + 0.025*\"shit\" + 0.022*\"baby\" + 0.020*\"change\" + 0.020*\"gender\" + 0.020*\"agree\" + 0.019*\"deal\" + 0.012*\"move\" + 0.011*\"visit\"'),\n",
       " (5,\n",
       "  '0.087*\"life\" + 0.032*\"leave\" + 0.023*\"job\" + 0.020*\"vaccinate\" + 0.017*\"free\" + 0.017*\"wife\" + 0.016*\"death\" + 0.014*\"risk\" + 0.012*\"whilst\" + 0.010*\"unvaccinated\"'),\n",
       " (6,\n",
       "  '0.065*\"pay\" + 0.021*\"mother\" + 0.015*\"continue\" + 0.013*\"forever\" + 0.012*\"street\" + 0.012*\"mind\" + 0.011*\"bite\" + 0.010*\"tax\" + 0.010*\"stock\" + 0.010*\"ago\"'),\n",
       " (7,\n",
       "  '0.036*\"shop\" + 0.035*\"freedom\" + 0.019*\"video\" + 0.017*\"career\" + 0.016*\"responsible\" + 0.016*\"service\" + 0.016*\"speak\" + 0.015*\"mild\" + 0.013*\"receive\" + 0.013*\"funny\"'),\n",
       " (8,\n",
       "  '0.074*\"mask\" + 0.044*\"wear\" + 0.031*\"rule\" + 0.030*\"choice\" + 0.030*\"protect\" + 0.028*\"spend\" + 0.026*\"restriction\" + 0.021*\"worker\" + 0.021*\"follow\" + 0.019*\"study\"'),\n",
       " (9,\n",
       "  '0.055*\"vaccine\" + 0.043*\"fuck\" + 0.039*\"lot\" + 0.033*\"spread\" + 0.033*\"business\" + 0.028*\"omicron\" + 0.026*\"kill\" + 0.018*\"god\" + 0.017*\"shoot\" + 0.017*\"catch\"')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics(num_words=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
